x<- 0:6
class(x)
as.numeric(x)
as.logical(x)
as.character(x)
x <- list (1,"a", T, 1+4i)
print(x)
m<-matrix(2,3)
print(m)
m
m<-matrix(1:6, nrow=2,ncol=3)
m
dim(m)<-c(2,5)
m<-1:10
m
dim(m)<-c(2,5)
m
x<-factor(c("yes","yes","no"))
x
table(x)
unclass(x)
is.na(x)
names(x)
names(x)<-c("foo","bar")
names(x)
x<-list(a=1,b=2,c=3)
x
x<-4
class(x)
x<-c(4,"a",TRUE)
class(x)
x<-c(1,3,5)
y<-c(3,2,10)
rbind(x,y)
x<-list(2,"a","b",TRUE)
x
x[[2]]
x<1:4
x<-1:4
y<-2:3
x+y
x<-c(3,5,1,10,12,6)
x[x<6]<-0
x
read.csv(hw1_data.csv)
read.csv(hw1_data.csv)
read.csv(file=hw1_data.csv)
read.csv("hw1_data.csv")
mydata <-read.csv("hw_data.csv")
getwd()
dir()
install.packages("dplyr")
library(dplyr)
system.time(readLines("http://www.jhsph.edu"))
hilbert <- function(n){
i <- 1:n
}
hilbert <- function (n) {
i <- 1:n
1/ outer (i - 1, i , "+")
}
x <- hilbert(1000)
system.time(svd(x))
Rprof()
lm(x)
set.seed(1)
rpois(5,2)
rpois(5,2)
set.seed(1)
rpois(5,2)
set.seed(2)
rpois(5,2)
rpois(5,2)
set.seed(10)
x <- rep(0:1, each=5)
e <- rnorm(10, 0, 20)
x
y <- 0.5 + 2 * x + E
y <- 0.5 + 2 * x + e
str(y)
library(datasets)
Rprof(Null)
Rprof(NULL)
Rprof()
fit <- lm(y ~ x1 + x2)
library(datasets)
help(mean)
mean()
?mean
args(mean)
library("lattice")
library("datasets")
data(airquality)
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
library("ggplot2")
library(ggplot2)
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github", "ClientID", "ClientSecret")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
req <- GET("https://api.github.com/rate_limit", config(token = github_token))
file.url <- 'http://biostat.jhsph.edu/~jleek/contact.html'
file.dest <- 'contact.html'
download.file(file.url, file.dest)
con <- file('contact.html')
lines <- readLines(con)
l10 <- lines[10]
l20 <- lines[20]
l30 <- lines[30]
l100 <- lines[100]
nchar(l10)
nchar(l20)
nchar(l30)
nchar(l100)
getdata <- read.fwf('getdata.for', skip=4, widths=c(12, 7,4, 9,4, 9,4, 9,4))
?rev()
?as.vector()
?append()
?sort()
?sum()
?seq()
?rep()
?seq()
?which()
?strptime
?diff
?strptime
library(dplyr)
?ends-with
?helper function
library(data.table)
x <- 1:4
p <- x/sum(x)
temp <- rbind(x, p)
rownames(temp) <- c("X", "Prob")
temp
sum(x*p)
x*p
pnorm(70,mean=80,sd=10,lower.tail = FALSE)
qnorm(95,mean=1100, sd=75)
qnorm(95,mean=1,100, sd=75)
qnorm(0,95,mean=1100, sd=75)
qnorm(0.95,mean=1100, sd=75)
qnorm(0.95,mean=1100, sd=7,5)
dbinom(k=4,n=5,p=0.5)
dbinom(4,5,0.5)
dbinom(5,5,0.5)
pnorm(16,mean=15,sd=10,lower.tail = TRUE)
pnorm(16,mean=15,sd=10,lower.tail = TRUE)-pnorm(14,mean=15,sd=10,lower.tail = TRUE)
pnorm(16,mean=15,sd=1,lower.tail = TRUE)-pnorm(14,mean=15,sd=1,lower.tail = TRUE)
ppois(10,15)
?rpart.control
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
install.packages(caret)
install.packages("caret")
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
install.packages("caret")
library(caret)
library(AppliedPredictiveModeling)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training= adData[trainIndex,]
testing=adData[-trainIndex,]
rbind("original dataset" = dim(adData),"training set" = dim(training))
adData = data.frame(predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
> training= adData[trainIndex,]
> testing=adData[-trainIndex,]
> rbind("original dataset" = dim(adData),"training set" = dim(training))
training= adData[trainIndex,]
testing=adData[-trainIndex,]
rbind("original dataset" = dim(adData),"training set" = dim(training))
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
library(ggplot2)
plot(mixtures$CompressiveStrength,col=mixtures$Age)
library(Hmisc)
install.packages("Hmisc")
install.packages("Hmisc")
cuttedAge <- cut2(mixtures$Age,4)
library(Hmisc)
cuttedAge <- cut2(mixtures$Age,4)
plot(mixtures$CompressiveStrength,col=cuttedAge)
cuttedAge <- cut2(mixtures$Age,g=4)
plot(mixtures$CompressiveStrength,col=cuttedAge)
qplot(mixtures$CompressiveStrength,col=cuttedAge)
plot(mixtures$CompressiveStrength)
plot(mixtures$CompressiveStrength,col=mixtures$FlyAsh)
summary(mixtures$FlyAsh)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
qplot(mixtures$CompressiveStrength,mixtures$Superplasticizer)
histogram(mixtures$CompressiveStrength,mixtures$Superplasticizer)
xnames <- colnames(concrete)[1:8]
featurePlot(x=training[, xnames], y=training$CompressiveStrength, plot="pairs")
index <- seq_along(1:nrow(training))
ggplot(data=training, aes(x=index, y=CompressiveStrength)) + geom_point() +
theme_bw()
cutCompressiveStrength <- cut2(training$CompressiveStrength, g=4)
ggplot(data=training, aes(y=index, x=cutCompressiveStrength)) +
geom_boxplot() + geom_jitter(col="blue") + theme_bw()
qplot(Superplasticizer, data=training)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
ss <- training[,grep('^IL', x = names(training) )]
preProc <- preProcess(ss, method='pca', thresh=0.9,
outcome=training$diagnosis)
preProc$rotation
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(3433)data(AlzheimerDisease)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
IL <- grep("^IL", colnames(training), value=TRUE)
ILpredictors <- predictors[, IL]
df <- data.frame(diagnosis, ILpredictors)
inTrain <- createDataPartition(df$diagnosis, p=3/4)[[1]]
training <- df[inTrain, ]
testing <- df[-inTrain, ]
modelFit <- train(diagnosis ~ .,method="glm",data=training)
library(caret)
modelFit <- train(diagnosis ~ .,method="glm",data=training)
modelFit <- train(diagnosis ~ ., method="glm", data=training)
predictions <- predict(modelFit, newdata=testing)
install.packages('e1071', dependencies=TRUE)
modelFit <- train(diagnosis ~ ., method="glm", data=training)
predictions <- predict(modelFit, newdata=testing)
C1 <- confusionMatrix(predictions, testing$diagnosis)
print(C1)
acc1 <- C1$overall[1]
acc1
modelFit <- train(training$diagnosis ~ .,
method="glm",
preProcess="pca",
data=training,
trControl=trainControl(preProcOptions=list(thresh=0.8)))
C2 <- confusionMatrix(testing$diagnosis, predict(modelFit, testing))
print(C2)
set.seed(3433)
IL <- grep("^IL", colnames(training), value=TRUE)
ILpredictors <- predictors[, IL]
df <- data.frame(diagnosis, ILpredictors)
inTrain <- createDataPartition(df$diagnosis, p=3/4)[[1]]
training <- df[inTrain, ]
testing <- df[-inTrain, ]
modelFit <- train(diagnosis ~ ., method="glm", data=training)
predictions <- predict(modelFit, newdata=testing)
C1 <- confusionMatrix(predictions, testing$diagnosis)
print(C1)
modelFit <- train(training$diagnosis ~ .,
method="glm",
preProcess="pca",
data=training,
trControl=trainControl(preProcOptions=list(thresh=0.8)))
C2 <- confusionMatrix(testing$diagnosis, predict(modelFit, testing))
print(C2)
acc2 <- C2$overall[1]
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
data <- segmentationOriginal
set.seed(125)
train <- data$Case == "Train"
TrainData <- data[train,]
TestData <- data[-train,]
TestData <- data[!train,]
model <- train(Class ~ . , data=TrainData, method="rpart")
print(model$finalModel)
rattle:: fancyRpartPlot(model$finalModel)
fancyRpartPlot(model$finalModel)
plot(model$finalModel)
plot(model$finalModel,uniform=T)
text(model$finalModel)
text(model$finalModel,cex=0.8)
library(pgmm)
data(olive)
olive = olive[,-1]
install.packages(pgmm)
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
tree <- train(Area ~ ., data=olive, method="rpart")
tree <- train(Area ~ ., data=olive, method="rpart2")
print(tree$finalModel)
predict(tree,newdata = as.data.frame(t(colMeans(olive))))
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
install.packages("ElemStatLearn")
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
logModel <- train(chd ~ age + alcohol + obesity + tobacco +
typea + ldl, data=trainSA, method="glm",
family="binomial")
logModel
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
predictTrain(logModel, trainSA)
predictTrain <- predict(logModel, trainSA)
predictTrain <- predict(logModel, testSA)
predictTrain <- predict(logModel, trainSA)
predictTest <- predict(logModel, testSA)
missClass(trainSA$chd, predictTrain)
missClass(testSA$chd, predictTest)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
RFmodel <- train(y ~ ., data=vowel.train,method="rf",prox=TRUE)
order(varImp(modelRf), decreasing=T)
order(varImp(RFmodel), decreasing=T)
varImp(RFmodel)
RFmodel <- train(y ~ ., data=vowel.train,method="rf",prox=TRUE,importance = FALSE)
order(varImp(RFmodel), decreasing=T)
varImp(RFmodel)
file <- url('https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv')
file
dat = read.csv("~/Desktop/gaData.csv")
dat = read.csv(file)
library(lubridate)
install.packages('lubridate')
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(lubridate)
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
summary(tstrain)
str(tstrain)
library("caret", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
install.packages('forecast')
library("AppliedPredictiveModeling", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
library(forecast)
bats(tstrain)
BATSmodel <- bats(tstrain)
forecast <- forecast(BATSmodel)
summary(forecast)
plot(forecast)
accuracy(forecast,testing)
tstest = ts(testing$visitsTumblr)
accuracy(forecast,testing$visitsTumblr)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
install.packages('e1071')
library('e1701')
library('e1071')
model <-svm(CompressiveStrength ~., data=training)
model <- train(CompressiveStrength ~. data=training, method="svmRadial")
model <- train(CompressiveStrength ~. ,data=training, method="svmRadial")
prediction <- predict(model,testing)
accuracy(prediction,testing$CompressiveStrength)
source('~/OneDrive/Documents/Data Science Specialization/Titanic-survival/Titanic-survival.R')
source('~/OneDrive/Documents/Data Science Specialization/Titanic-survival/Titanic-survival.R')
source('~/OneDrive/Documents/Data Science Specialization/Titanic-survival/Titanic-survival.R')
source('~/OneDrive/Documents/Data Science Specialization/Titanic-survival/Titanic-survival.R')
randomForest$importance
source('~/OneDrive/Documents/Data Science Specialization/Titanic-survival/Titanic-survival.R')
source('~/OneDrive/Documents/Data Science Specialization/Titanic-survival/Titanic-survival.R')
